{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying DNA Sequences\n",
    "## Description\n",
    "Explore the world of bioinformatics by using Markov models, KNN, SVM and other common classifiers to classify short E. Coli DNA sequences.\n",
    "\n",
    "## Dataset \n",
    "The dataset for this project was taken from the UCI Machine Learning Repository that includes 106 DNA sequences, with 57 sequential nucleotides each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]\n",
      "numpy: 1.16.2\n",
      "sklearn: 0.20.3\n",
      "pandas: 0.24.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Python: {}\".format(sys.version))\n",
    "print(\"numpy: {}\".format(np.__version__))\n",
    "print(\"sklearn: {}\".format(sklearn.__version__))\n",
    "print(\"pandas: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/molecular-biology/promoter-gene-sequences/promoters.data'\n",
    "names = ['Class', 'id', 'Sequence']\n",
    "data = pd.read_csv(url, names = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class                                                       +\n",
      "id                                                        S10\n",
      "Sequence    \\t\\ttactagcaatacgcttgcgttcggtggttaagtatgtataat...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# load a sample record\n",
    "print(data.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    +\n",
      "1    +\n",
      "2    +\n",
      "3    +\n",
      "4    +\n",
      "Name: Class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# preprocessing the dataset\n",
    "classes = data.loc[:, 'Class']\n",
    "print(classes[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'a', 'c', 't', 'a', 'g', 'c', 'a', 'a', 't', 'a', 'c', 'g', 'c', 't', 't', 'g', 'c', 'g', 't', 't', 'c', 'g', 'g', 't', 'g', 'g', 't', 't', 'a', 'a', 'g', 't', 'a', 't', 'g', 't', 'a', 't', 'a', 'a', 't', 'g', 'c', 'g', 'c', 'g', 'g', 'g', 'c', 't', 't', 'g', 't', 'c', 'g', 't', '+']\n"
     ]
    }
   ],
   "source": [
    "# generate list of DNA sequences \n",
    "sequences = list(data.loc[:, 'Sequence'])\n",
    "dataset = {}\n",
    "\n",
    "# loop through sequences and split into individual nucleotides\n",
    "for i, seq in enumerate(sequences):\n",
    "    # split into nucleotides and split into individual nucleotides\n",
    "    nucleotides= list(seq)\n",
    "    nucleotides = [x for x in nucleotides if x != '\\t']\n",
    "    \n",
    "    # append class assignment\n",
    "    nucleotides.append(classes[i])\n",
    "    \n",
    "    # add to the dataset\n",
    "    dataset[i] = nucleotides\n",
    "    \n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   1   2   3   4   5   6   7   8   9    ... 96  97  98  99  100 101 102  \\\n",
      "0    t   t   g   a   t   a   c   t   c   t  ...   c   c   t   a   g   c   g   \n",
      "1    a   g   t   a   c   g   a   t   g   t  ...   c   g   a   g   a   c   t   \n",
      "2    c   c   a   t   g   g   g   t   a   t  ...   g   c   t   a   g   t   a   \n",
      "3    t   t   c   t   a   g   g   c   c   t  ...   a   t   g   g   a   c   t   \n",
      "4    a   a   t   g   t   g   g   t   t   a  ...   g   a   a   g   g   a   t   \n",
      "5    g   t   a   t   a   c   g   a   t   a  ...   t   g   c   g   c   a   c   \n",
      "6    c   c   g   g   a   a   g   c   a   a  ...   a   g   c   t   a   t   t   \n",
      "7    a   c   a   a   t   a   t   a   a   t  ...   g   a   g   g   t   g   c   \n",
      "8    a   t   g   t   t   g   g   a   t   t  ...   a   c   a   t   g   g   a   \n",
      "9    t   g   a   g   a   g   g   a   a   t  ...   c   t   a   a   t   c   a   \n",
      "10   a   a   a   t   a   a   a   a   t   c  ...   c   t   c   c   c   c   c   \n",
      "11   c   c   c   g   c   g   g   c   a   c  ...   c   t   g   t   a   t   a   \n",
      "12   g   a   t   t   t   g   g   a   c   t  ...   t   c   a   c   g   c   a   \n",
      "13   c   g   a   a   a   a   a   c   t   c  ...   t   t   g   c   c   t   g   \n",
      "14   t   t   g   t   t   t   t   t   g   t  ...   a   t   t   a   c   a   a   \n",
      "15   t   t   t   c   t   g   t   t   c   t  ...   g   g   c   a   t   a   t   \n",
      "16   g   g   g   g   g   g   t   g   g   g  ...   a   t   a   g   c   a   t   \n",
      "17   c   t   c   a   a   a   a   a   a   t  ...   g   t   a   a   g   c   a   \n",
      "18   g   c   a   a   c   a   a   t   c   c  ...   a   g   t   a   a   g   a   \n",
      "19   t   a   t   g   g   a   g   a   a   a  ...   g   a   c   g   c   g   c   \n",
      "20   t   c   t   t   a   g   c   c   g   g  ...   c   t   a   a   a   g   c   \n",
      "21   c   g   a   g   a   a   c   t   g   g  ...   a   t   g   g   a   t   g   \n",
      "22   g   c   g   t   a   g   a   g   a   c  ...   t   t   a   g   c   c   a   \n",
      "23   g   t   c   g   a   g   t   t   c   c  ...   g   t   c   a   t   t   c   \n",
      "24   t   g   t   t   g   t   c   a   g   g  ...   t   c   c   a   t   t   a   \n",
      "25   g   a   t   t   c   t   t   t   t   g  ...   c   c   g   g   g   g   g   \n",
      "26   g   t   a   g   t   g   c   g   c   a  ...   a   a   c   a   c   a   a   \n",
      "27   t   t   t   c   g   c   c   a   c   a  ...   g   t   t   t   a   g   t   \n",
      "28   t   g   t   g   a   c   t   g   g   t  ...   c   g   t   g   t   g   t   \n",
      "29   a   g   t   g   a   g   g   c   t   a  ...   c   c   t   a   a   g   c   \n",
      "30   a   t   t   a   a   t   a   a   t   a  ...   t   g   g   g   a   g   a   \n",
      "31   g   g   t   g   a   a   t   t   c   c  ...   c   g   a   g   a   t   a   \n",
      "32   t   t   t   t   c   t   g   a   t   t  ...   g   t   c   c   t   t   t   \n",
      "33   a   c   t   a   c   a   a   c   g   c  ...   a   g   t   t   g   t   c   \n",
      "34   t   g   g   g   a   a   c   a   t   c  ...   c   t   c   a   c   t   t   \n",
      "35   g   t   t   a   c   a   g   g   g   c  ...   a   t   t   g   t   t   c   \n",
      "36   t   t   t   t   t   g   c   t   t   t  ...   a   t   g   a   t   t   g   \n",
      "37   a   a   a   g   a   a   a   a   a   a  ...   c   t   g   c   t   g   t   \n",
      "38   t   c   t   t   g   a   t   t   a   t  ...   t   g   t   g   c   c   g   \n",
      "39   a   a   c   t   a   a   a   a   a   a  ...   t   c   a   t   t   t   g   \n",
      "40   a   a   a   a   a   c   g   a   t   a  ...   g   g   t   c   t   g   a   \n",
      "41   t   t   t   g   t   t   t   t   c   t  ...   c   c   t   t   g   a   t   \n",
      "42   g   c   g   a   g   a   c   t   g   g  ...   a   a   a   c   t   a   g   \n",
      "43   c   t   c   a   c   g   a   g   c   c  ...   t   a   c   t   a   a   g   \n",
      "44   g   a   t   t   g   a   g   c   a   g  ...   a   t   t   g   g   g   a   \n",
      "45   c   a   a   a   c   g   c   t   a   c  ...   a   g   g   c   a   g   c   \n",
      "46   g   c   a   c   c   t   c   t   t   c  ...   a   t   t   a   c   a   g   \n",
      "47   g   g   c   t   t   c   c   c   g   a  ...   t   t   g   t   g   g   t   \n",
      "48   g   c   c   a   c   c   a   a   a   c  ...   g   a   a   g   t   g   t   \n",
      "49   c   a   a   a   c   g   t   a   a   c  ...   c   a   a   g   g   a   c   \n",
      "50   t   t   c   c   g   t   c   c   a   a  ...   t   t   c   a   c   a   a   \n",
      "51   t   c   c   a   t   t   a   a   t   c  ...   t   c   a   g   c   c   a   \n",
      "52   g   g   c   a   g   t   t   g   g   t  ...   t   g   t   t   c   t   c   \n",
      "53   t   c   g   a   g   a   g   a   g   g  ...   c   c   t   a   t   a   a   \n",
      "54   c   c   g   c   t   g   a   a   t   a  ...   t   t   a   t   a   t   t   \n",
      "55   g   a   c   t   a   g   a   c   t   c  ...   t   t   t   g   c   a   t   \n",
      "56   t   a   g   c   g   t   t   a   t   a  ...   g   t   t   a   g   t   g   \n",
      "57   +   +   +   +   +   +   +   +   +   +  ...   -   -   -   -   -   -   -   \n",
      "\n",
      "   103 104 105  \n",
      "0    c   c   t  \n",
      "1    g   t   a  \n",
      "2    c   c   a  \n",
      "3    g   g   c  \n",
      "4    a   t   a  \n",
      "5    c   c   t  \n",
      "6    t   c   t  \n",
      "7    a   t   a  \n",
      "8    c   c   a  \n",
      "9    g   a   t  \n",
      "10   a   a   a  \n",
      "11   t   t   a  \n",
      "12   g   g   a  \n",
      "13   a   g   t  \n",
      "14   g   c   a  \n",
      "15   a   c   a  \n",
      "16   t   t   g  \n",
      "17   g   c   g  \n",
      "18   c   t   a  \n",
      "19   c   a   g  \n",
      "20   t   a   g  \n",
      "21   g   a   c  \n",
      "22   a   c   t  \n",
      "23   g   g   c  \n",
      "24   t   g   t  \n",
      "25   g   g   a  \n",
      "26   c   t   a  \n",
      "27   t   c   t  \n",
      "28   t   t   g  \n",
      "29   c   t   g  \n",
      "30   c   g   c  \n",
      "31   g   a   a  \n",
      "32   t   g   c  \n",
      "33   t   g   t  \n",
      "34   a   g   c  \n",
      "35   c   g   a  \n",
      "36   t   t   t  \n",
      "37   g   t   t  \n",
      "38   g   t   a  \n",
      "39   a   t   g  \n",
      "40   t   t   c  \n",
      "41   t   t   c  \n",
      "42   g   g   a  \n",
      "43   t   c   a  \n",
      "44   c   t   t  \n",
      "45   a   g   c  \n",
      "46   c   a   a  \n",
      "47   c   a   a  \n",
      "48   a   a   t  \n",
      "49   a   g   c  \n",
      "50   g   g   a  \n",
      "51   g   a   a  \n",
      "52   c   g   g  \n",
      "53   t   g   a  \n",
      "54   t   a   a  \n",
      "55   c   a   c  \n",
      "56   c   c   t  \n",
      "57   -   -   -  \n",
      "\n",
      "[58 rows x 106 columns]\n"
     ]
    }
   ],
   "source": [
    "# convert the dataset to pandas df\n",
    "df = pd.DataFrame(dataset)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  1  2  3  4  5  6  7  8  9   ... 48 49 50 51 52 53 54 55 56 57\n",
      "0  t  a  c  t  a  g  c  a  a  t  ...  g  c  t  t  g  t  c  g  t  +\n",
      "1  t  g  c  t  a  t  c  c  t  g  ...  c  a  t  c  g  c  c  a  a  +\n",
      "2  g  t  a  c  t  a  g  a  g  a  ...  c  a  c  c  c  g  g  c  g  +\n",
      "3  a  a  t  t  g  t  g  a  t  g  ...  a  a  c  a  a  a  c  t  c  +\n",
      "4  t  c  g  a  t  a  a  t  t  a  ...  c  c  g  t  g  g  t  a  g  +\n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# transpose the dataframe\n",
    "df = df.transpose()\n",
    "print(df.iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4  5  6  7  8  9  ... 48 49 50 51 52 53 54 55 56 class\n",
      "0  t  a  c  t  a  g  c  a  a  t  ...  g  c  t  t  g  t  c  g  t     +\n",
      "1  t  g  c  t  a  t  c  c  t  g  ...  c  a  t  c  g  c  c  a  a     +\n",
      "2  g  t  a  c  t  a  g  a  g  a  ...  c  a  c  c  c  g  g  c  g     +\n",
      "3  a  a  t  t  g  t  g  a  t  g  ...  a  a  c  a  a  a  c  t  c     +\n",
      "4  t  c  g  a  t  a  a  t  t  a  ...  c  c  g  t  g  g  t  a  g     +\n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# rename the last col to class\n",
    "df.rename(columns={57:'class'}, inplace=True)\n",
    "print(df.iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>t</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9  ...   48   49   50  \\\n",
       "count   106  106  106  106  106  106  106  106  106  106  ...  106  106  106   \n",
       "unique    4    4    4    4    4    4    4    4    4    4  ...    4    4    4   \n",
       "top       t    a    a    c    a    a    a    a    a    a  ...    c    c    c   \n",
       "freq     38   34   30   30   36   42   38   34   33   36  ...   36   42   31   \n",
       "\n",
       "         51   52   53   54   55   56 class  \n",
       "count   106  106  106  106  106  106   106  \n",
       "unique    4    4    4    4    4    4     2  \n",
       "top       t    t    c    c    c    t     +  \n",
       "freq     33   35   32   29   29   34    53  \n",
       "\n",
       "[4 rows x 58 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1     2     3     4     5     6     7     8     9  ...    48  \\\n",
      "t  38.0  26.0  27.0  26.0  22.0  24.0  30.0  32.0  32.0  28.0  ...  21.0   \n",
      "c  27.0  22.0  21.0  30.0  19.0  18.0  21.0  20.0  22.0  22.0  ...  36.0   \n",
      "a  26.0  34.0  30.0  22.0  36.0  42.0  38.0  34.0  33.0  36.0  ...  23.0   \n",
      "g  15.0  24.0  28.0  28.0  29.0  22.0  17.0  20.0  19.0  20.0  ...  26.0   \n",
      "+   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "-   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "\n",
      "     49    50    51    52    53    54    55    56  class  \n",
      "t  22.0  23.0  33.0  35.0  30.0  23.0  29.0  34.0    NaN  \n",
      "c  42.0  31.0  32.0  21.0  32.0  29.0  29.0  17.0    NaN  \n",
      "a  24.0  28.0  27.0  25.0  22.0  26.0  24.0  27.0    NaN  \n",
      "g  18.0  24.0  14.0  25.0  22.0  28.0  24.0  28.0    NaN  \n",
      "+   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   53.0  \n",
      "-   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   53.0  \n",
      "\n",
      "[6 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# record value counts for each sequence\n",
    "series = []\n",
    "for name in df.columns:\n",
    "    series.append(df[name].value_counts())\n",
    "    \n",
    "info = pd.DataFrame(series)\n",
    "details = info.transpose()\n",
    "print(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_a</th>\n",
       "      <th>0_c</th>\n",
       "      <th>0_g</th>\n",
       "      <th>0_t</th>\n",
       "      <th>1_a</th>\n",
       "      <th>1_c</th>\n",
       "      <th>1_g</th>\n",
       "      <th>1_t</th>\n",
       "      <th>2_a</th>\n",
       "      <th>2_c</th>\n",
       "      <th>...</th>\n",
       "      <th>55_a</th>\n",
       "      <th>55_c</th>\n",
       "      <th>55_g</th>\n",
       "      <th>55_t</th>\n",
       "      <th>56_a</th>\n",
       "      <th>56_c</th>\n",
       "      <th>56_g</th>\n",
       "      <th>56_t</th>\n",
       "      <th>class_+</th>\n",
       "      <th>class_-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_a  0_c  0_g  0_t  1_a  1_c  1_g  1_t  2_a  2_c  ...  55_a  55_c  55_g  \\\n",
       "0    0    0    0    1    1    0    0    0    0    1  ...     0     0     1   \n",
       "1    0    0    0    1    0    0    1    0    0    1  ...     1     0     0   \n",
       "2    0    0    1    0    0    0    0    1    1    0  ...     0     1     0   \n",
       "3    1    0    0    0    1    0    0    0    0    0  ...     0     0     0   \n",
       "4    0    0    0    1    0    1    0    0    0    0  ...     1     0     0   \n",
       "\n",
       "   55_t  56_a  56_c  56_g  56_t  class_+  class_-  \n",
       "0     0     0     0     0     1        1        0  \n",
       "1     0     1     0     0     0        1        0  \n",
       "2     0     0     0     1     0        1        0  \n",
       "3     1     0     1     0     0        1        0  \n",
       "4     0     0     0     1     0        1        0  \n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert string data to numerical \n",
    "numerical_df = pd.get_dummies(df)\n",
    "numerical_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0_a  0_c  0_g  0_t  1_a  1_c  1_g  1_t  2_a  2_c  ...  54_t  55_a  55_c  \\\n",
      "0    0    0    0    1    1    0    0    0    0    1  ...     0     0     0   \n",
      "1    0    0    0    1    0    0    1    0    0    1  ...     0     1     0   \n",
      "2    0    0    1    0    0    0    0    1    1    0  ...     0     0     1   \n",
      "3    1    0    0    0    1    0    0    0    0    0  ...     0     0     0   \n",
      "4    0    0    0    1    0    1    0    0    0    0  ...     1     1     0   \n",
      "\n",
      "   55_g  55_t  56_a  56_c  56_g  56_t  class  \n",
      "0     1     0     0     0     0     1      1  \n",
      "1     0     0     1     0     0     0      1  \n",
      "2     0     0     0     0     1     0      1  \n",
      "3     0     1     0     1     0     0      1  \n",
      "4     0     0     0     0     1     0      1  \n",
      "\n",
      "[5 rows x 229 columns]\n"
     ]
    }
   ],
   "source": [
    "# two class columns are not neccessary, so drop one of them, let's choose class_-\n",
    "df = numerical_df.drop(columns=['class_-'])\n",
    "\n",
    "df.rename(columns={'class_+': 'class'}, inplace=True)\n",
    "print(df.iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training and testing datasets\n",
    "from sklearn import model_selection\n",
    "\n",
    "# create input X and output y datasets for training\n",
    "X = np.array(df.drop(['class'], axis=1))\n",
    "y = np.array(df['class'])\n",
    "\n",
    "# define random seed\n",
    "seed = 42\n",
    "\n",
    "# split data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training classification algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors: 0.796429 (0.085714)\n",
      "Gaussian Process: 0.907143 (0.126471)\n",
      "Decision Tree: 0.821429 (0.141512)\n",
      "Random Forest: 0.621429 (0.191630)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net: 0.908929 (0.087646)\n",
      "AdaBoost: 0.860714 (0.117857)\n",
      "Naive Bayes: 0.885714 (0.118235)\n",
      "SVM Linear: 0.896429 (0.099681)\n",
      "SVM RBF: 0.833929 (0.140164)\n",
      "SVM Sigmoid: 0.608929 (0.202889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# define scoring methods \n",
    "scoring = 'accuracy'\n",
    "\n",
    "# define training models\n",
    "names = [\"Nearest Neighbors\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"SVM Linear\", \"SVM RBF\", \"SVM Sigmoid\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_neighbors = 3),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    SVC(kernel = 'linear'), \n",
    "    SVC(kernel = 'rbf'),\n",
    "    SVC(kernel = 'sigmoid')\n",
    "]\n",
    "\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state = seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    \n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors\n",
      "0.8148148148148148\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.74        12\n",
      "           1       0.75      1.00      0.86        15\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        27\n",
      "   macro avg       0.88      0.79      0.80        27\n",
      "weighted avg       0.86      0.81      0.80        27\n",
      "\n",
      "Gaussian Process\n",
      "0.8888888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        12\n",
      "           1       0.83      1.00      0.91        15\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        27\n",
      "   macro avg       0.92      0.88      0.88        27\n",
      "weighted avg       0.91      0.89      0.89        27\n",
      "\n",
      "Decision Tree\n",
      "0.7777777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67        12\n",
      "           1       0.71      1.00      0.83        15\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        27\n",
      "   macro avg       0.86      0.75      0.75        27\n",
      "weighted avg       0.84      0.78      0.76        27\n",
      "\n",
      "Random Forest\n",
      "0.5925925925925926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.50      0.52        12\n",
      "           1       0.62      0.67      0.65        15\n",
      "\n",
      "   micro avg       0.59      0.59      0.59        27\n",
      "   macro avg       0.59      0.58      0.58        27\n",
      "weighted avg       0.59      0.59      0.59        27\n",
      "\n",
      "Neural Net\n",
      "0.8518518518518519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80        12\n",
      "           1       0.79      1.00      0.88        15\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        27\n",
      "   macro avg       0.89      0.83      0.84        27\n",
      "weighted avg       0.88      0.85      0.85        27\n",
      "\n",
      "AdaBoost\n",
      "0.9259259259259259\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        12\n",
      "           1       0.93      0.93      0.93        15\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        27\n",
      "   macro avg       0.93      0.93      0.93        27\n",
      "weighted avg       0.93      0.93      0.93        27\n",
      "\n",
      "Naive Bayes\n",
      "0.9259259259259259\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        12\n",
      "           1       1.00      0.87      0.93        15\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        27\n",
      "   macro avg       0.93      0.93      0.93        27\n",
      "weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "SVM Linear\n",
      "0.8518518518518519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80        12\n",
      "           1       0.79      1.00      0.88        15\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        27\n",
      "   macro avg       0.89      0.83      0.84        27\n",
      "weighted avg       0.88      0.85      0.85        27\n",
      "\n",
      "SVM RBF\n",
      "0.8518518518518519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        12\n",
      "           1       0.87      0.87      0.87        15\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        27\n",
      "   macro avg       0.85      0.85      0.85        27\n",
      "weighted avg       0.85      0.85      0.85        27\n",
      "\n",
      "SVM Sigmoid\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73        12\n",
      "           1       1.00      0.40      0.57        15\n",
      "\n",
      "   micro avg       0.67      0.67      0.67        27\n",
      "   macro avg       0.79      0.70      0.65        27\n",
      "weighted avg       0.81      0.67      0.64        27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(name)\n",
    "    print(accuracy_score(y_test, predictions))\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
